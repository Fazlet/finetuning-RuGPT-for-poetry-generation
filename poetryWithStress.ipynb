{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pJbYXou6chZf",
    "outputId": "44925472-8f1c-44b6-e664-9c882409d6b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 17 17:13:24 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   39C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3RlwU_QNH8oO",
    "outputId": "84b53382-809d-4605-8980-d40e4ae9f0b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: gitpython in /usr/local/lib/python3.7/dist-packages (3.1.17)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions>=3.7.4.0; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from gitpython) (3.7.4.3)\n",
      "Requirement already satisfied, skipping upgrade: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from gitpython) (4.0.7)\n",
      "Requirement already satisfied, skipping upgrade: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->gitpython) (4.0.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.0)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (8.0.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -U gitpython\n",
    "!pip3 install transformers\n",
    "!pip3 install urllib3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0hpfgIcuINt8",
    "outputId": "ff68b141-d29b-4a46-ac26-b635a710cbbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rmq8Ca7yIN4t"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "import gc\n",
    "import copy\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from collections import Counter\n",
    "import itertools\n",
    "#from nltk.tokenize import word_tokenize\n",
    "#from nltk.corpus import stopwords\n",
    "#import nltk\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "#import matplotlib.ticker as ticker\n",
    "#import matplotlib.dates as mdates\n",
    "#import seaborn as sns\n",
    "#plt.style.use('bmh')\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer, GPT2Tokenizer, GPT2LMHeadModel, GPT2Config, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import Dataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn import functional as F\n",
    "\n",
    "pd.set_option('display.max_rows', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SfMFTHrB-D-T"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i_JAmHUEIN62"
   },
   "outputs": [],
   "source": [
    "data_path = \"./drive/MyDrive/anna/data/accentedPoems.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vqxYNvazIN9A"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tfeUNNTH-Ffk"
   },
   "outputs": [],
   "source": [
    "data.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "jOeNJB6aQBEi",
    "outputId": "19f53f05-f9ee-48d0-9a20-5426f422225b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>В первом до̀ме ро̀бко и до̀лго жѝл я в дѐтст...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Кака̀я химѐра\\nмой ра̀зум имѐла,\\nмой ра̀зум...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Кто пьѐт одѝн, тот пьѐт с умо̀м\\nс умо̀м св...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Не вѝдно о̀строу̀мных ра̀сстава̀ний\\nво тьмѐ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ни ша̀тко ни ва̀лко гудѝт кофева̀рка,\\nгудѝ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54183</th>\n",
       "      <td>Читателю\\n\\nПервы труд мой в французском приим...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54184</th>\n",
       "      <td>Элегия о смерти Петра Великого\\n\\nЧто за печал...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54185</th>\n",
       "      <td>СТЯЖАТЕЛЯ СИХ КНИГ ПОСЛЕДНЕЕ КНИГАМ ЦЕЛОВАНИЕ\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54186</th>\n",
       "      <td>О титулы, пропасти паче вас назва̀ти,\\nКоль вы...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54187</th>\n",
       "      <td>Ты, облеченна в солнце, Дево Богома̀ти,\\nДа ка...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54188 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "0      В первом до̀ме ро̀бко и до̀лго жѝл я в дѐтст...\n",
       "1      Кака̀я химѐра\\nмой ра̀зум имѐла,\\nмой ра̀зум...\n",
       "2      Кто пьѐт одѝн, тот пьѐт с умо̀м\\nс умо̀м св...\n",
       "3      Не вѝдно о̀строу̀мных ра̀сстава̀ний\\nво тьмѐ...\n",
       "4      Ни ша̀тко ни ва̀лко гудѝт кофева̀рка,\\nгудѝ,...\n",
       "...                                                  ...\n",
       "54183  Читателю\\n\\nПервы труд мой в французском приим...\n",
       "54184  Элегия о смерти Петра Великого\\n\\nЧто за печал...\n",
       "54185  СТЯЖАТЕЛЯ СИХ КНИГ ПОСЛЕДНЕЕ КНИГАМ ЦЕЛОВАНИЕ\\...\n",
       "54186  О титулы, пропасти паче вас назва̀ти,\\nКоль вы...\n",
       "54187  Ты, облеченна в солнце, Дево Богома̀ти,\\nДа ка...\n",
       "\n",
       "[54188 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "Dx3d72Hv-Si9",
    "outputId": "cf8103de-6019-4053-bcd4-f416b3840c53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53579\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>в первом до̀ме ро̀бко и до̀лго жѝл я в дѐтст...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>кака̀я химѐра\\nмой ра̀зум имѐла,\\nмой ра̀зум...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>кто пьѐт одѝн, тот пьѐт с умо̀м\\nс умо̀м св...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>не вѝдно о̀строу̀мных ра̀сстава̀ний\\nво тьмѐ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ни ша̀тко ни ва̀лко гудѝт кофева̀рка,\\nгудѝ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53574</th>\n",
       "      <td>читателю\\n\\nпервы труд мой в французском приим...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53575</th>\n",
       "      <td>элегия о смерти петра великого\\n\\nчто за печал...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53576</th>\n",
       "      <td>стяжателя сих книг последнее книгам целование\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53577</th>\n",
       "      <td>о титулы, пропасти паче вас назва̀ти,\\nколь вы...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53578</th>\n",
       "      <td>ты, облеченна в солнце, дево богома̀ти,\\nда ка...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53579 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "0      в первом до̀ме ро̀бко и до̀лго жѝл я в дѐтст...\n",
       "1      кака̀я химѐра\\nмой ра̀зум имѐла,\\nмой ра̀зум...\n",
       "2      кто пьѐт одѝн, тот пьѐт с умо̀м\\nс умо̀м св...\n",
       "3      не вѝдно о̀строу̀мных ра̀сстава̀ний\\nво тьмѐ...\n",
       "4      ни ша̀тко ни ва̀лко гудѝт кофева̀рка,\\nгудѝ,...\n",
       "...                                                  ...\n",
       "53574  читателю\\n\\nпервы труд мой в французском приим...\n",
       "53575  элегия о смерти петра великого\\n\\nчто за печал...\n",
       "53576  стяжателя сих книг последнее книгам целование\\...\n",
       "53577  о титулы, пропасти паче вас назва̀ти,\\nколь вы...\n",
       "53578  ты, облеченна в солнце, дево богома̀ти,\\nда ка...\n",
       "\n",
       "[53579 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(df):\n",
    "    new_texts = []\n",
    "    texts = df['text'].values\n",
    "    for i in range(len(texts)):\n",
    "        texts[i] = texts[i].lower()\n",
    "        texts[i] = re.sub(\"[0-9]\", \"\", texts[i])\n",
    "        texts[i] = re.sub(' +', ' ', texts[i])\n",
    "        if len(texts[i]) >= 100:\n",
    "            new_texts.append(texts[i])\n",
    "    print(len(new_texts))\n",
    "    new_df = pd.DataFrame(data=new_texts, columns=['text'])\n",
    "    return new_df\n",
    "\n",
    "data = preprocess(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fWK5WTNsN2Ew",
    "outputId": "a8224a21-0fd8-44d5-df12-e68a33f51b61"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/models/auto/modeling_auto.py:810: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelWithLMHead.from_pretrained('sberbank-ai/rugpt3large_based_on_gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9iemhClYE3j6"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MI2f49p-OZ9o",
    "outputId": "be35059c-7f3f-4fab-cf12-9cb0eaa48ff4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('sberbank-ai/rugpt3large_based_on_gpt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u845yUVltOKJ"
   },
   "source": [
    "### **ОБУЧЕНИЕ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EHg2Vp7NOZ_x"
   },
   "outputs": [],
   "source": [
    "raw = data['text'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rzWLGxKIPDhJ"
   },
   "outputs": [],
   "source": [
    "tokens = [tokenizer.encode(text) for text in raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zyEhOU2dPDjZ",
    "outputId": "27e3a799-71c9-4160-9095-227a235207ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5357"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_start_index = int(len(raw) * 0.1)\n",
    "validation_start_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R_uSilB1PUS8",
    "outputId": "778562e1-1e3a-41f3-eabe-930c6d8188fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53579/53579 [00:00<00:00, 2343709.80it/s]\n"
     ]
    }
   ],
   "source": [
    "train_lengths = [len(token) for token in tqdm(tokens)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mzg4dKmiHGsi",
    "outputId": "c024937c-c9f3-48b4-a91f-4807d97f3fae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50257\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OXjru621PUVN"
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "random_seed = 420\n",
    "torch.manual_seed(random_seed)\n",
    "max_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LsnNTh2QQckl"
   },
   "outputs": [],
   "source": [
    "special_tokens_dict = {'pad_token': '<PAD>', 'bos_token': '<BOS>', 'eos_token': '<EOS>'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kx54druhIeiL"
   },
   "outputs": [],
   "source": [
    "pad_index = 50258\n",
    "boc_index = 50259\n",
    "eoc_index = 50260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CmtIZzDLQlTz"
   },
   "outputs": [],
   "source": [
    "num_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ai0q7491QYbd"
   },
   "outputs": [],
   "source": [
    "class PoetryDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts = texts\n",
    "        self.max_len = max_length\n",
    "\n",
    "    def __len__(self):        \n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        text = self.texts[index]\n",
    "        text = f'{text}'\n",
    "        \n",
    "        enc_dict = tokenizer(text, truncation=True, max_length=self.max_len)\n",
    "        tokenized = enc_dict['input_ids']\n",
    "        \n",
    "        return torch.tensor(tokenized).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-NWlbPkBIOGo",
    "outputId": "2f3c2652-7ee4-4c62-d930-c17583359394"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53579, 5358)"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poems_train = PoetryDataset(raw, tokenizer, max_len)\n",
    "poems_valid = PoetryDataset(raw[::10], tokenizer, max_len)\n",
    "\n",
    "len(poems_train), len(poems_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gjaTSgpUIOKw"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(poems_train,\n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=True)\n",
    "\n",
    "validation_loader = DataLoader(poems_valid, \n",
    "                               batch_size=batch_size, \n",
    "                               shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Px8lDzUcRnB7"
   },
   "outputs": [],
   "source": [
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ibt5aQ7RRnEB"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "warmup_steps = 50\n",
    "total_steps = len(train_loader) * num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "exsQa-40Dqo1",
    "outputId": "a5203550-d58f-4edf-9bca-8ac577bc62c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50261, 1536)"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7SlixMq6RnGM"
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nP1fo5gXRnIT"
   },
   "outputs": [],
   "source": [
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps=warmup_steps,\n",
    "                                            num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mxpVNGzhSOGU"
   },
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, scheduler, last_n_losses=200, verbose=True):\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    progress_bar = tqdm(total=len(loader.dataset), disable=not verbose, desc='Train')\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for tokens in loader:\n",
    "\n",
    "        tokens = tokens.to(device)\n",
    "        \n",
    "        outputs = model(tokens)\n",
    "\n",
    "        shift_tokens = tokens[..., 0:].contiguous()\n",
    "        shift_logits = outputs.logits[..., :, :].contiguous()\n",
    "\n",
    "        losses_vec = F.cross_entropy(shift_logits.view(-1, shift_logits.size(-1)), shift_tokens.view(-1), reduction=\"none\")\n",
    "\n",
    "        coeffs = torch.ones(list(losses_vec.size())[0]).cuda()\n",
    "        indexes = (shift_tokens == 206).nonzero(as_tuple=True)[1]\n",
    "        for index in indexes:\n",
    "            if index > 1:\n",
    "                coeffs[index - 1] *= 3\n",
    "                coeffs[index - 2] *= 3\n",
    "\n",
    "        losses_vec = coeffs*losses_vec\n",
    "\n",
    "        loss = losses_vec.mean()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.zero_grad()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        progress_bar.set_postfix(loss=np.mean(losses[-last_n_losses:]),\n",
    "                                 perplexity=np.exp(np.mean(losses[-last_n_losses:])))\n",
    "        \n",
    "        progress_bar.update()\n",
    "\n",
    "    progress_bar.close()\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QFySnwqCSOI2"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, loader, last_n_losses=200, verbose=True):\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    progress_bar = tqdm(total=len(loader), disable=not verbose, desc='Evaluate')\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for tokens in loader:\n",
    "\n",
    "        tokens = tokens.to(device)\n",
    "        \n",
    "        outputs = model(tokens)\n",
    "\n",
    "        shift_tokens = tokens[..., 0:].contiguous()\n",
    "        shift_logits = outputs.logits[..., :, :].contiguous()\n",
    "\n",
    "        losses_vec = F.cross_entropy(shift_logits.view(-1, shift_logits.size(-1)), shift_tokens.view(-1), reduction=\"none\")\n",
    "\n",
    "        coeffs = torch.ones(list(losses_vec.size())[0]).cuda()\n",
    "        indexes = (shift_tokens == 206).nonzero(as_tuple=True)[1]\n",
    "        for index in indexes:\n",
    "            if index > 1:\n",
    "                coeffs[index - 1] *= 3\n",
    "                coeffs[index - 2] *= 3\n",
    "\n",
    "        losses_vec = coeffs*losses_vec\n",
    "\n",
    "        loss = losses_vec.mean()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "\n",
    "        progress_bar.set_postfix(loss=np.mean(losses[-last_n_losses:]),\n",
    "                                 perplexity=np.exp(np.mean(losses[-last_n_losses:])))\n",
    "        \n",
    "        progress_bar.update()\n",
    "\n",
    "    progress_bar.close()\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KzdTm29kRnKf"
   },
   "outputs": [],
   "source": [
    "save_best_model_path = './drive/MyDrive/anna/rhyme_best_model_state_dict.pth'\n",
    "save_best_optimizer_path = './drive/MyDrive/anna/rhyme_best_optimizer_state_dict.pth'\n",
    "save_last_model_path = './drive/MyDrive/anna/rhyme_last_model_state_dict.pth'\n",
    "save_last_optimizer_path = './drive/MyDrive/anna/rhyme_last_optimizer_state_dict.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G0QHIDEwKRCR"
   },
   "outputs": [],
   "source": [
    "# ЧИСТИМ ПАМЯТЬ ПЕРЕД ОБУЧЕНИЕМ\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 539
    },
    "id": "iImqa9kLTHlQ",
    "outputId": "ec45095d-9080-4ce4-9ff7-ca619ccef255"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 53579/53579 [3:31:58<00:00,  4.21it/s, loss=9.75, perplexity=1.72e+4]\n",
      "Evaluate: 100%|██████████| 5358/5358 [04:03<00:00, 22.00it/s, loss=10.2, perplexity=2.66e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train: loss - 9.7601 | perplexity - 17327.577\n",
      "Validation: loss - 10.2009 | perplexity - 26927.454\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0mnum_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-5fa8ad43ffbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_optimizer_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_end_of_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:274] . unexpected pos 972703616 vs 972703504"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "train_perplexities = []\n",
    "validation_perplexities = []\n",
    "\n",
    "best_validation_loss = 1e+6\n",
    "\n",
    "for n_epoch in range(1, num_epochs + 1):\n",
    "    \n",
    "    epoch_train_losses = train(model, train_loader, optimizer, scheduler)\n",
    "\n",
    "    torch.save(model.state_dict(), save_last_model_path)\n",
    "    torch.save(optimizer.state_dict(), save_last_optimizer_path)\n",
    "\n",
    "    epoch_validation_losses = evaluate(model, validation_loader)\n",
    "    \n",
    "    mean_train_loss = np.mean(epoch_train_losses)\n",
    "    mean_validation_loss = np.mean(epoch_validation_losses)\n",
    "    \n",
    "    train_losses.extend(epoch_train_losses)\n",
    "    train_perplexities.append(np.exp(mean_train_loss))\n",
    "    \n",
    "    validation_losses.extend(epoch_validation_losses)\n",
    "    validation_perplexities.append(np.exp(mean_validation_loss))\n",
    "    \n",
    "    message = f'Epoch: {n_epoch}\\n'\n",
    "    message += f'Train: loss - {mean_train_loss:.4f} | perplexity - {train_perplexities[-1]:.3f}\\n'\n",
    "    message += f'Validation: loss - {mean_validation_loss:.4f} | perplexity - {validation_perplexities[-1]:.3f}'\n",
    "    \n",
    "    print(message)\n",
    "    \n",
    "    #\n",
    "    #if mean_validation_loss < best_validation_loss:\n",
    "    #    \n",
    "    #    best_validation_loss = mean_validation_loss\n",
    "    #    \n",
    "    #    torch.save(model.state_dict(), save_best_model_path)\n",
    "    #    torch.save(optimizer.state_dict(), save_best_optimizer_path)\n",
    "    #    \n",
    "    #else:\n",
    "    #    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6-CfXcM8AJNZ"
   },
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), save_best_model_path)\n",
    "#torch.save(optimizer.state_dict(), save_best_optimizer_path)\n",
    "\n",
    "#torch.save(model.state_dict(), save_last_model_path)\n",
    "#torch.save(optimizer.state_dict(), save_last_optimizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vZBTw_8HTHnW",
    "outputId": "d5f9f6da-7e15-46b5-dbb8-6237f6e1ee26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./drive/MyDrive/anna/rhyme_last_model_state_dict.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Az_StK7vc2JA"
   },
   "outputs": [],
   "source": [
    "optimizer.load_state_dict(torch.load('./drive/MyDrive/anna/rhyme_last_optimizer_state_dict.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "4AXGEOt0THp3"
   },
   "outputs": [],
   "source": [
    "def write_poem(snippet, length, tokenizer, model):\n",
    "    input_text = f'{snippet}'\n",
    "    inds = tokenizer(input_text, return_tensors='pt')['input_ids'].to(device)\n",
    "    text = model.generate(\n",
    "        input_ids=inds,\n",
    "        max_length=length + len(inds),\n",
    "        do_sample=True,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        temperature=0.9,\n",
    "        no_repeat_ngram_size=20,\n",
    "        pad_token_id = 50258\n",
    "        )\n",
    "    poem = tokenizer.decode(text[0])\n",
    "    #poem = poem.strip(f'')\n",
    "    return poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VD0B4fcTPDzn",
    "outputId": "ae39c474-e609-4725-b22f-1b34d2bbbd83"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50261, 1536)\n",
       "    (wpe): Embedding(2048, 1536)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): GPT2Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): GPT2Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): GPT2Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): GPT2Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): GPT2Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): GPT2Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (18): GPT2Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (19): GPT2Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (20): GPT2Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (21): GPT2Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (22): GPT2Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (23): GPT2Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=50261, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mmXY8wkEXQSN",
    "outputId": "038b180d-1912-46b7-95c2-bce380c1416b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ни ша̀тко ни ва̀лко гудѝт кофева̀рка,\n",
      "гудѝ, виртуо̀зка, гудѝ.\n",
      "поту̀хли огнѝ моего̀ фейервѐрка,\n",
      "одна̀ только ко̀поть в грудѝ.\n",
      "така̀я там ко̀поть, что хо̀чется пла̀кать.\n",
      "ах, э̀то не прѝхоть моя̀!\n",
      "моя̀ комсомо̀лка присла̀ла на па̀мять\n",
      "косы̀нку краснѐе огня̀.\n",
      "присла̀ла косы̀нку, а что̀ мне в ней то̀лку,\n",
      "когда̀ только ко̀поть в грудѝ?\n",
      "вертѝсь же быстрѐе, моя̀ кофемо̀лка,\n",
      "гудѝ, умоля̀ю, гудѝ!\n",
      "\n",
      "майо̀р нурутдѝнов кого̀-то свирѐпо\n",
      "оклѝкнул и вы̀шел на свя̀зь.\n",
      "смешна̀я дрезѝна включѝла сирѐну\n",
      "и мѝмо кусто̀в пронесла̀сь.\n",
      "кляну̀сь, я там бы̀л и смотрѐл дерзновѐнно\n",
      "сквозь лѝстьев и стра̀хов сквозь слё̀з,\n",
      "как мѝмо, терза̀я цвету̀щие вѐтви,\n",
      "возмѐздие вда̀ль унесло̀сь.\n",
      "дрезѝна взревѐла и вско̀ре умо̀лкла,\n",
      "утѝхли и слѐзы моѝ.\n",
      "танцу̀й же быстрѐе, моя̀ виртуо̀зка,\n",
      "и пла̀менем кра̀сным горѝ\n",
      "\n",
      "май \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(raw[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oFiX4dvHXWJt",
    "outputId": "07bf96b6-0b28-4587-86bf-19898760a336"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ни ша̀тко ни ва̀лко гудѝт кофева̀рка\n",
      "\n",
      "В этот день в Советском Союзе прошли выборы в Верховный совет СССР. В избирательный бюллетень были включены две фамилии, и от каждой из них исходили\n"
     ]
    }
   ],
   "source": [
    "poem = write_poem('ни ша̀тко ни ва̀лко гудѝт кофева̀рка\\r\\n', 50, tokenizer, model)\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VVNadQhhX2-J",
    "outputId": "56a3be43-a5f8-4c87-98c3-07a572351d98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ни ша̀тко ни ва̀лко гудѝт кофева̀рка̀...\n",
      "\n",
      "— Ва̀лко, да̀мба̀л! — на̀кричал̀ я.\n",
      "\n",
      "— Бэ̀л, да̀мба̀л! — повторил̀ он.\n",
      "\n",
      "— С̀амба̀л? — закричал̀ я.\n",
      "\n",
      "— Та̀л!\n",
      "\n",
      "— Кака̀?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "poem = write_poem('ни ша̀тко ни ва̀лко гудѝт кофева̀рка', 100, tokenizer, model)\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q__r55R9X8GC",
    "outputId": "45aa4d74-8c77-4f43-c0fd-06ec306216b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ни шатко ни валко гудит кофеварка. Как можно было бы все испортить, если бы не эта дурочка, за которой я приехал на такси и которую мне приходится, вопреки моим ожиданиям, ждать до семи утра.\n",
      "\n",
      "— Пожалуй, я лучше пойду, — говорит она, — мне еще надо приготовить кое-что.\n",
      "\n",
      "— Конечно, конечно, — говорю я, — но, пожалуй, я тоже пойду.\n",
      "\n",
      "— Нет\n"
     ]
    }
   ],
   "source": [
    "poem = write_poem('ни шатко ни валко гудит кофеварка', 100, tokenizer, model)\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3MnjdRdzYMAd",
    "outputId": "8f6ed4be-61cd-4c73-c3ec-b1f4c941b89d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "пионерские пруды\n",
      "\n",
      "москва̀ о ско̀лько в э̀том ква̀ке\n",
      "лягу̀шечьѐй игры̀ и ла̀сковы̀х имѐн\n",
      "строѐнья со̀ловьѝныѐ бара̀ки\n",
      "аква̀риу̀м иллю̀зио̀н\n",
      "\n",
      "заря̀ над пѝонѐрскимѝ пруда̀ми\n",
      "как бы̀ и впра̀вду пѐрвая̀ заря̀\n",
      "над мѝром о̀бновлѐнным, со̀ следа̀ми\n",
      "от па̀триа̀рха ѝ царя̀\n",
      "\n",
      "но стѐртымѝ бледнѐющѝми в го̀рнем\n",
      "арха̀нгельско̀м сия̀ниѝ фанфа̀р\n",
      "и вѐрится̀ что са̀м ты вы̀рван с ко̀рнем\n",
      "подбро̀шен ввѐрх как пѐрвома̀йский ша̀р\n",
      "\n",
      "и про̀плыва̀ешь на̀д своѐй столѝцей\n",
      "бескры̀лой кру̀глой тѐнью пѐрвоптѝцы\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(raw[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jIo-sZnATHr8",
    "outputId": "a49d6924-1339-4de0-f555-aeec98a23286"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "москва̀ о ско̀лько в э̀том ква̀кѐ? \n",
      "\n",
      "Уговорили! Устроили! \n",
      "\n",
      "- А вы знаете, - говорит мать, - к нам приезжает товарищ из Москвы. \n",
      "\n",
      "- Товарищ\n"
     ]
    }
   ],
   "source": [
    "poem = write_poem('москва̀ о ско̀лько в э̀том ква̀ке', 50, tokenizer, model)\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R2vN47opScQZ",
    "outputId": "730e5550-495e-444f-e9d3-5308166421b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "с днём рождения поздравляю\n",
      "С днём рождения!!!!<s>\n",
      "Натюрморт с изображением женщины. С днём рождения поздравляю! Счастья, любви, здоровья, успехов, благополучия!\n",
      "спасибо большое, только вот... женщина за столом - это же\n"
     ]
    }
   ],
   "source": [
    "poem2 = write_poem('с днём рождения поздравляю\\r\\n', 50, tokenizer, model)\n",
    "print(poem2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "aO93e7rZTHuK"
   },
   "outputs": [],
   "source": [
    "text7 = f'россия великая наша держава\\r\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hYIyEKQwIOPI",
    "outputId": "c088692a-b96b-4f46-9514-6aba2ca76546"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1584,   274, 28652,  5571,  4985,   342,   206,   203]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids7 = tokenizer(text7, return_tensors='pt')['input_ids'].to(device)\n",
    "input_ids7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "WRYbDuJjhQb3"
   },
   "outputs": [],
   "source": [
    "out7 = model.generate(\n",
    "    input_ids=input_ids7,\n",
    "    max_length=max_len + len(input_ids7),\n",
    "    do_sample=True,\n",
    "    no_repeat_ngram_size=20,\n",
    "    pad_token_id = 50258\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yanzznhfU8iR",
    "outputId": "7fad2f69-a2b1-425c-d5e4-f9aa7a8ded01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1584,   274, 28652,  5571,  4985,   342,   206,   203,   203,   732,\n",
       "          1858,    16,  3226,    16,  3226,   349, 16490,  7023, 14704,  1642,\n",
       "            16,  1642,   723,   203,  1140,   436, 31370,    18,   889,   322,\n",
       "           309, 33015, 21566,    18,   203,  3693, 23136,  3226,  7023, 14704,\n",
       "          1642,    16,  1642,   723,     1,   203,   672,   345,   613,   727,\n",
       "           337,  3646,   376,  2197,   411,  3322, 11241, 36800, 22544,  1437,\n",
       "           294,  3798,  5123,   458,  1182,   337,  3646,     6, 12702,  7975,\n",
       "         14241, 11088, 32384, 32460,    18,   203,  4441,  2361,   411, 27132,\n",
       "         16471,    16,  2486,   519,  4319,  1326, 12256,   282,  5806,  9578,\n",
       "         16864,    18,   203,   677,  1335,   575,  8372,   656,  3984, 13880,\n",
       "           289]], device='cuda:0')"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "SlJ0S8iJhQeF",
    "outputId": "ac929c92-05cb-4844-b9e4-a58d78898c8b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'россия великая наша держава\\r\\n\\nИ снова, опять, опять за окном мелькают дома, дома...\\nУспокойся. Это не на прогулку идем.\\nЗа окнами опять мелькают дома, дома...<s>\\nПтица Феникс - одна из самых известных литературных иллюстраций к роману \"Феникс\" великого русского поэта Сергея Есенина.\\nЭто одно из немногих произведений, которое до сих пор живо в памяти современных читателей.\\nВ этой же книге мы будем рассматривать и'"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text7 = tokenizer.decode(out7[0])\n",
    "generated_text7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "go42fEuqUekB",
    "outputId": "a0f06a90-1ce7-43a6-c11c-86e2b48321af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "россия великая наша держава\n",
      "\n",
      "И снова, опять, опять за окном мелькают дома, дома...\n",
      "Успокойся. Это не на прогулку идем.\n",
      "За окнами опять мелькают дома, дома...<s>\n",
      "Птица Феникс - одна из самых известных литературных иллюстраций к роману \"Феникс\" великого русского поэта Сергея Есенина.\n",
      "Это одно из немногих произведений, которое до сих пор живо в памяти современных читателей.\n",
      "В этой же книге мы будем рассматривать и\n"
     ]
    }
   ],
   "source": [
    "print(generated_text7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rDxrmY5KUemY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "poetryWithStress.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
